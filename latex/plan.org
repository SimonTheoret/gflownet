#+title:     Planification rapport final (LaTeX)
#+author:    Simon Théorêt
#+email:     simonteoret@hotmail.com

* GFlowChess Latex
** Sections
Rappel CCC: Contexte Contenu Conclusion
*** Abstract
**** Contexte
- [X] Alpha Zero: Citer papier 
- [X] Gflownet
- [X] Self play
- [ ] Stockfish
**** Contenu
- [X] Deux pertes différentes
- [X] Deux fonctions de récompenses
**** Conclusion 
- [X] Changer comportement global des trajectoires
- [X] Comportement agressifs ?
- [X] Favoriser un joueur.
*** Introduction (contexte, motivation, résumé)
**** Contexte
- [X] Taille de l'espace des parties possibles
- [X] Complexité stratégique
- [X] 'Résolu' par AlphaZero
  - [X] Objectif n'est pas de faire compétition à alpha go
- [ ] Différent de /Maia/: objectif n'est pas de concevoir un modèl
    qui imite le comportement humain
**** Contenu
- [X] Donc, GFlowNet est approprié:
  "Les modèles génératifs GFlowNet sont particulièrement bien adaptés
  au cas des échecs de par le rg déroulement séquentiel d’une partie
  et le vaste potentiel d’exploration des meilleurs stratégie"
- [X] But: Explorer comment modifier fonctions de pertes/récompenses
  change la façon dont se comporte le modèle entraîné
- [X] Récompense intermédiaire: Flow-Matching/Forward-Looking. Semble être le meilleur choix
**** Conclusion
- [X] Capable de modifier comportement du modèle pour beaucoup favorise
  un seul joueur
- [ ] N'apprends pas forcément de bonnes stratégies
- [ ] Difficulté rencontrées: Flow-Matching/Forward-Looking loss, ~get_parents()~,
  entraînement long, dépendance à stockfish, difficulté à évaluer
  qualité des parties (score final, mais stratégies douteuses)
*** Revue de la littérature
Discuter de GFlowNet comme un modèle génératif récent. J'aimerais y
inclure une référence vers la Trajectory Balance et Forward Looking
loss, intermediary step. Voici les sources:
# - [[https://arxiv.org/abs/2106.04399][Flow Matching Loss]]  pas la bonne loss
- [[https://arxiv.org/abs/2201.13259][Trajectory Balance Loss]]
- [[https://arxiv.org/abs/2302.01687][Forward Looking loss]]
Mentionner l'excellente documentation de l'équipe de Stockfish: [[https://github.com/official-stockfish/nnue-pytorch/blob/master/docs/nnue.md#halfkp][Docs]]?
Mentionner l'usage de GFlowNet en contexte de [[https://arxiv.org/abs/2310.02779][zero-sum
games]]. Important de discuter de [[https://arxiv.org/abs/2006.01855][Maia]] , un modèle qui réplique le
comportement humain. Finalement, citer AlphaZero, un programme plus
général que seulement au échec mais qui a battu les meilleurs
programmes d'échec.
**** Contexte
- [X] GFlowNet comme modèle récent
- [X] Échecs déjà touché par le ML:
  - [X] Stockfish, un moteur d'échec (évaluation)
  - [X] Maia, un modèle qui joue comme un humain
  - [X] AlphaZero, le sur-humain
**** Contenu
- [X] Introduire FlowMatching ou Forward Looking loss
- [X] Introduire Trajectory Balance
- [X] Discuter de Stockfish comme outils d'évaluation
- [X] Parler de Zero-sum games (environnement stochastique)
**** Conclusion
- [X] Récent mais plein de promesse (mettons)
*** Méthodes
Reprendre et améliorer le contenu de devoir 'final'
**** Contexte
- [X] Aborder rapidement la complexité des échecs
- [X] Environnement non stochastique: GFlowNet joue contre lui-même
- [X] Implémenté avec librairie du prof
- [X] Usage de la librairie python-chess pour simuler notre environnement
**** Contenu
- [X] Choix de proxy (parler de nos deux choix)
- [X] Multi-processing pour Stockfish
- [X] Fonction de pertes
- [X] Prendre quelques images de plateau
- [X] Chialer sur ~get_parents()~
- [X] Transformer (*parse*) Board en tenseur avec encoding one-hot
- [X] Simplification quant au mouvement bizzare
**** Conclusion
- [ ] Tâche grandement simplifié par l'existence de librairies
- [ ] Quelques difficultés techiniques aux niveau de l'environnment
  (chialer encore sur ~get_parents()~)
*** Résultats
**** Contexte
- [ ] Sous section entraînement avec les hyperparamètres
  - [ ] Nombre de pas max pour un match
  - [ ] Nombre d'itérations
- [ ] Choix des deux fonctions de pertes
- [ ] Choix de proxy (récompense)
**** Contenu
- [ ] Montrer fonction de perte:
  - [ ] Monter TB: belle convergence
  - [ ] Montre forward looking: pas de convergence
- [ ] Présenter et comparer les deux fonction de récompenses
- [ ] Discuter du biais de victoire (absent, présent, ampleur)
- [ ] Distribution du nombre de pièces mangées (visualisations!)
- [ ] Distribution du score
- [ ] Distribution des probabilités de victoire
- [ ] Discuter du temps d'entraînement
- [ ] Montrer une partie échantillonnée complète en annexe
**** Conclusion
- [ ] Entraînement de stockfish est A-OK
- [ ] Capacité à orienter le modèle à faire gagner un joueur
- [ ] Limitation quand au comportement de modèle car environnement non
  stochastique
*** Conclusions
**** Contexte
- [ ] Entraîné GFlowNet
**** Contenu
- [ ] Capable de le biaiser
- [ ] Principal facteur d'intérêt est la fonction de récompense
**** Conclusion
- [ ] FUTUR: Concevoir un environnement stochastique avec GFlowNet et les
  échecs.
*** Contributions
Demander aux 'participants d'y inscrire leur contributions (/lol/)
*** Références
Utiliser références de [[file:~/Downloads/revuelit.pdf][revue de littérature]] 
